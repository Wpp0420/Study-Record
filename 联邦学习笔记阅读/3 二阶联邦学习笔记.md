# 3 二阶联邦学习笔记

## 1.简介

提出了一种基于空中计算（Over-the-AirComputation）技术的二阶联邦优化方法，以此可以同时实现联邦学习中==总通信轮数==的减少和==全局模型聚合延迟==的降低。



本工作从无线通信场景下的==联邦学习系统==、==训练方法==、==通信模型==三个维度出发构建了一个新型的联邦学习框架，

并在复杂场景下（如数据异构性、设备选择不确定性、无线信道噪声等）对其训练的==收敛性==进行了严格的数学证明和理论分析，

然后基于收敛性分析结果设计了一==种针对设备选择和波束赋形==的联合优化方法。



该工作一方面基于空中计算技术利用==多接入信道中波束的叠加特性==实现了低延迟的模型聚合，

另一方面通过==二阶算法的快速收敛特性==大大减少了训练迭代轮数，有效解决了当前无线联邦学习方法所饱受的通信瓶颈问题。

同时，通过所提出的==联合优化方法==进一步提升了训练的精确度。

## 2.全文阅读

###  1 abstract

然而，FL可能导致在有限的无线电资源下的无线网络上产生面向任务的数据流量流。

为了设计通信高效的FL，现有的研究大多采用了收敛速度较慢的一阶联邦优化方法。

然而，这导致了对边缘设备和边缘服务器之间的本地模型更新的**过度通信轮询**。communication rounds 



为了解决这一问题，本文提出了一种新的无线二阶联合优化算法，以同时**减少通信轮数**，并实现**低延迟**的全局模型聚合。

这是通过利用多接入信道的波形叠加特性，在无线网络上实现分布式二阶优化算法来实现的。

 This is achieved by exploiting the waveform superposition property of a multi-access

channel to implement the distributed second-order optimization algorithm over wireless networks.

进一步表征了该算法的收敛性，揭示了在每次迭代中具有累积误差项的线性-二次收敛速度。

 The convergence behavior of the proposed algorithm is further characterized, which reveals **a linear-quadratic convergence rate** with **an accumulative error term** in each iteration.

因此，我们提出了一种通过联合器件选择和波束形成设计来最小化累积误差间隙的系统优化方法。数值结果表明，与现有方法相比，该系统和通信效率。

We thus propose a system optimization approach to **minimize the accumulated error gap** by joint **device selection and beamforming design**. Numerical results demonstrate the system and communication efficiency compared with the state-of the-art approaches.

### 1 instruction

#### 	1 概况（到论文中）

首先，服务器向所有涉及的设备广播当前的全局模型参数。接下来，每个设备根据其本地数据进行本地模型训练，然后将本地更新发送回服务器。最后，服务器对局部更新进行聚合，并为分布式训练的下一次迭代生成新的全局模型参数。

在本质上，服务器和设备的目标是协同解决一个分布式优化问题，这通常被称为联邦优化[5]。与集中式优化不同，联邦优化面临着通信效率、数据异构性、安全性、系统复杂性等诸多实际挑战

####  2 通信效率

其中，**通信效率**至关重要，因为服务器和设备之间的通信通常存在不可靠的网络连接、资源有限和严重的延迟

为了解决通信问题，人们在联邦优化方面进行了大量的研究。一方面，在每次迭代中**减少通信量**是一种有效的方法。具体地说，采用量化和稀疏化技术来减少传输位和去除参数的冗余更新，分别为[8]，[9]。这些压缩技术对高维模型显示出了显著的有效性。然而，它们的设计需要考虑到在FL [6]中进行聚合操作的兼容性。

另一方面，**最小化总通信轮数**是另一种主要方法。为此，研究了零阶方法[10]，[11]在一些限制性情况下（如黑盒对抗攻击，非光滑目标函数），同时显示出巨大的潜力，因为只需要目标函数值来近似导数信息[12]。

在梯度可用的情况下，一阶方法被广泛使用。通过增加局部计算量，各种基于梯度下降的方法可以显著减少总通信轮数

然而，这些现有的方法，即零阶和一阶方法，在最佳情况下是**受线性收敛的控制**的。因此，为达到期望的精度所需的==总迭代轮数是相对较大==的[16]。

####  3 二阶算法

因此，**二阶方法**（如牛顿型方法）由于其快速的局部二次收敛速度而在这种无线环境中具有吸引力。

然而，规范牛顿更新的构建同时需要黑森信息和梯度信息，其中FL的分布情况使得收集黑森信息成为一个严重的通信开销。为此，我们研究了二阶联邦优化算法来解决这一问题，它可分为两类==[16]==

the construction of the canonical Newton update requires both the Hessian and gradient information

一是**隐式地使用二阶信息**。在==[17]==中，对局部函数进行镜像下降更新，以近似黑森信息。

In [17], a mirror descent update is carried out on the local function to approximate the Hessian

information.

在==[18]==中，利用目标函数的对偶问题作为局部子问题。

In [18], the dual problems of the objective function are used to serve as the local subproblems.

另一种类型是**显式地使用二阶信息**。

在[19]中，提出了一种利用局部黑森进行聚合的全局改进的近似牛顿法（巨牛）。

在[20]，[21]中，梯度范数的优化作为替代函数。

在[22]中，分别在设备和服务器上进行黑森向量乘积计算和共轭梯度下降。

在[22]中，分别在设备和服务器上进行黑森向量乘积计算和共轭梯度下降。

In [19], a globally improved approximate Newton method (GIANT) using local Hessian for aggregation is proposed.

In [20], [21], the optimization of the gradient’s norm acts as the surrogate function. 

In [22],Hessian-vector product computation and conjugate gradient descent are performed on the devices

and the server, respectively.

这些二阶算法的快速收敛速度使其应用具有很大的好处

####  4.延迟

尽管二阶算法在减少通信总轮数和提高通信效率方面具有应用潜力，但由于无线信道的传输噪声较大，资源有限，[23]-[25]延迟较高。

基于传统的“发射再通信”原理，可以通过数字编码传输和正交多址（OMA）方案[26]-[28]来实现FL模型参数的聚合。通过利用OMA和纠错技术，本地更新以量化的形式单独传输，然后在服务器上单独解码。这样，就可以认为模型传输是可靠的和值得信赖的。

然而，设备数量的增加将不可避免地导致总通信延迟和带宽需求的急剧增加，这往往是无法容忍的。因此，在FL算法设计中出现了一种新的空中计算（==AirComp==）[29]技术，以降低通信成本

基于“计算时传输”原理。该技术利用多接入通道的叠加特性，实现了聚合操作。通过同时传输所有通过空中聚合的本地更新，通信管理费用大大减少。具体来说，[30]的作者提出了一种基于aircomp的FL方法，即联合设计设备选择和波束形成，以提高统计学习性能。

在[32]中，提出了一种新的基于梯度的多址访问（GBMA）算法，采用能量尺度律来执行FL，以接近集中训练的收敛速度。在[35]中，作者研究了功率控制优化，以提高空中联合学习的学习性能。在[34]，[40]中，采用智能反射面（IRS）技术实现了快速而可靠的模型聚合的空中联邦学习。[36]的作者提出了基于aircomp的FL的动态学习率设计。总的来说，无线计算在FL中的应用也大大提高了通信效率。

####  5.总结

基于以上观察结果，本文提出从**减少了通信回合**和**每一轮的通信开销**两个方面来提高通信效率。为了减少交流轮数，我们将在FL的训练过程中利用二阶信息。由于快速的收敛速度，所有这些现有的二阶技术技术与一阶方法相比，在总迭代轮数方面都有了很大的改进。然而，他们的迭代过程在每次迭代中仍然至少==有两个通信轮，即梯度信息和二阶信息的聚合==。为了避免这种两轮通信，最近提出的一种二阶方法==[41]==减少了梯度的聚集，实现了每次迭代的一轮通信。基于此，我们采用**局部牛顿步长聚合算法**进行无线FL算法的设计。

具体地说，**利用局部海森反演和局部梯度的乘积来构造一个聚合的局部牛顿阶跃**。通过这种方法，设备每次迭代只需要与服务器通信一次，减少了局部黑森矩阵和局部梯度的传输，同时保持了**典型牛顿方法的收敛行为**。

此外，由于无线电资源有限，我们采用无线计算，在现有的无线FL方案中广泛使用，以进一步减少每一轮的通信开销。基于这种有效的局部牛顿步长聚合和AirComp技术，我们提出了一种在无线网络上的无线二阶联合算法。此外，我们还对我们所提出的方法的收敛行为进行了严格的理论分析。结果显示

结果表明，上述乘积的传输足以保证收敛性，并且我们所提出的方法优于一阶算法。具体来说，该算法**保持了线性二次收敛速度，即可以以二次收敛速度达到最优点，并在足够接近最优点时退化为线性收敛速度**。然而，由于局部牛顿步长聚合、设备选择和信道噪声，在每次迭代中都有一个误差项。随着训练的进行，这个==**累积误差项**==将使模型参数偏转，并影响学习性能。为了减轻该误差项的影响，我们进一步提出了一种设备选择和接收波束形成的==联合优化方法==。具体来说，采用吉布斯采样[42]来确定所选器件的集合，并针对吉布斯采样过程定制凸函数差（DC）算法[43]来优化迭代过程中的接收波束形成

#### 1A 贡献

本文采用二阶优化方法，提出了一种新的空中FL算法。然后，从理论上分析了其收敛性，结果表明该算法保持线性二次收敛速度，在FL过程中产生一个**累积误差项**。为了最小化误差差距并获得更好的性能，我们将这个问题表示为一个**组合非凸问题**，并提出了一种**系统优化方法**来解决它。本文的主要贡献总结如下

1)利用分布式二阶优化方法的原理，利用无线多址信道的波形叠加特性进行模型聚合，设计了一种基于aircomp的FL算法。该算法与现有的大多数在训练中只考虑梯度下降/SGD的算法有根本的不同。二阶信息的利用显著降低了基于空中通信系统的总通信轮数，进一步提高了通信效率。

2)我们从理论上分析了我们提出的空中二阶联合优化算法在存在数据异质性（即不同的数据大小）的情况下，设备选择和信道噪声的收敛行为。结果表明，该算法保持了线性二次收敛速度，且优于一阶方法；

3)我们提出了一个系统优化问题，以最小化该算法在执行过程中的累积误差间隙。相应地，我们提出了一个系统优化方法通过结合吉布斯采样和直流算法，我们共同优化了设备的选择和接收波束的形成；

4)我们进行了广泛的实验，以证明我们提出的算法和系统优化方法可以比其他先进的方法获得更好的性能



B.本文的其余部分组织如下。

第二节介绍了联邦学习模型和我们的FL算法。

第三节提供了我们所提出的算法的收敛性分析。

第四节分析了由误差项引起的系统优化问题，并描述了我们的器件选择和波束形成的联合优化方法。‘实验结果在第五节中给出。

k·kp是`p-范数，k·kF是弗罗贝尼乌斯范数。斜体、黑体、小写字母和大写字母分别表示标量、向量和矩阵。对于一个给定的集合X，|X |表示X的基数。算子（·）T、（·）H、Tr（·）和diag（·）分别表示转座矩阵、厄米特转座矩阵、轨迹矩阵和对角矩阵。E表示统计期望。

![image-20240420124145491](Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240420124145491.png)

## 2.联邦学习模型与算法

### *A. Federated Learning System*

==好用！抄到论文里!==

### *B. Federated Second-Order Optimization Algorithm*

梯度下降法（如SGD [44]，批处理梯度下降）作为典型的训练算法得到了广泛的应用。然而，梯度下降的收敛速度相对较慢，导致服务器和设备之间的通信轮数太多，无法完成学习任务。因此，为了提高梯度下降的通信效率，人们已经进行了大量的研究工作。

例如，一些方法利用多个本地更新来减少通信轮数[2]、[13]，而一些算法使用压缩技术来减少传输位和节省通信成本[8]、[9]、[45]。虽然这些方案极大地提高了FL中梯度下降的通信效率，但仍受到==线性收敛速度（延伸出去到最优化学习了）==的限制。

为了解决这一问题，本文考虑了收敛速度较快的二阶算法，从而可以显著减少了通信轮数。典型牛顿法[46]的下降方向向量由

**典型的牛顿方法可以实现局部二次收敛速度，使其完成学习任务所需的总迭代次数比一阶算法要少得多。**

![image-20240421213829486](Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240421213829486.png)

![image-20240421213836790](Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240421213836790.png)

这种数据矩阵的传输不可避免地带来巨大的通信开销。为了解决这个问题，人们提出了许多二阶分布式机器学习算法，如DANE ==[17]==、DISCO [22]、巨型==[19]==、DINGO ==[20]==和DINO ==[21]==。

这些方法**（1）以不同的形式近似于黑森信息**，以**避免黑森矩阵的直接传输，并接近正则牛顿方法的性能**。然而，每次迭代至少需要**两轮通信，包括局部梯度和二阶下降方向的聚集**。与这些二阶算法不同，

这需要局部梯度<img src="Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240421213706505.png" alt="image-20240421213706505" style="zoom:33%;" />的聚合来计算全局梯度，最近提出的一种同志**[41]**方法减少了这种聚合。

这样，每次迭代所需的**（2）通信轮数减少到1个**，进一步提高了通信效率。在此基础上，我们利用**==局部牛顿步长聚合（3）==**，以更少的通信轮实现更快的收敛速度

利用局部黑森矩阵<img src="Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240421214220728.png" alt="image-20240421214220728" style="zoom:33%;" />和局部梯度<img src="Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240421214232931.png" alt="image-20240421214232931" style="zoom:33%;" />的反演乘积作为模型聚合的局部下降方向向量<img src="Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240421214247389.png" alt="image-20240421214247389" style="zoom:33%;" />

（之前：<img src="Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240421214332979.png" alt="image-20240421214332979" style="zoom:33%;" />）



这样，在保持牛顿方法的收敛性的情况下，每次迭代只对d维局部下降方向向量进行一次聚合。具体来说，在第t次迭代时，我们所提出的方法的**过程总结如**下：

1)设备选择：服务器决定参与此迭代的设备集合，表示为St。

2)全局模型广播：服务器通过无线信道将当前的全局模型参数向量wt传播到所选设备。

3)局部模型更新：第i台设备接收到全局模型参数向量wt后，首先基于局部数据样本计算局部梯度：

![image-20240421214504648](Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240421214504648.png)

其中，这是关于第一个参数的导数。然后，第i个设备根据局部梯度和局部数据样本计算局部Hessian矩阵：

![image-20240421214537198](Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240421214537198.png)

然后，第i个装置从之前的结果中得到一个局部牛顿下降方向向量：

![image-20240421214623544](Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240421214623544.png)

在实际应用中，这一步涉及到黑森矩阵的计算及其逆运算。为了降低计算复杂度，我们采用**共轭梯度法**[46]得到了一个近似的局部牛顿下降方向向量。根据[19]的分析，这个**近似**解不会对收敛行为产生显著影响。

4)模型聚合：参与第t次迭代的设备通过无线信道向服务器发送局部牛顿下降方向向量{pt，i}，服务器对其进行聚合，得到本次迭代的全局下降方向向量：

![image-20240421214730360](Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240421214730360.png)

5)全局模型更新：最后，服务器通过全局下降方向向量˜pt和学习速率↵更新模型参数向量wt。<img src="Piuture_3%20%E4%BA%8C%E9%98%B6%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/image-20240421214757669.png" alt="image-20240421214757669" style="zoom:33%;" />

值得注意的是，牛顿的方法比梯度下降方法收敛速度快，因为它充分利用损失函数的曲率信息，但⇥的聚合局部黑森矩阵牛顿下降方向(3)以另一种方式加重通信开销。

正如我们提出的FL方案的第3步)所暗示的，它不需要计算局部梯度rF (w)和Hessian r2F (w)，通过聚合局部rFi (w)和r2Fi (w)来得到精确的牛顿下降方向。

需要注意的是，这种近似也给精确的下降方向向量带来了一个可控的误差间隙，它对收敛速度的影响将在第三节中进行分析